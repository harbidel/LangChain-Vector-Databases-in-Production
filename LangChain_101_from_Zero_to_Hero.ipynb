{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRnyS426vPwsZDP6x4kpQW"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hP4GFy7vgbPk"
      },
      "outputs": [],
      "source": [
        "!pip install langchain==0.0.208 deeplake openai tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The LLMs"
      ],
      "metadata": {
        "id": "BUbDm1qgnv6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "VmtcWtrqg_g2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Before executing the following code, make sure to have\n",
        "# your OpenAI key saved in the “OPENAI_API_KEY” environment variable.\n",
        "\n",
        "llm = OpenAI(model=\"text-davinci-003\", temperature=0.9)\n"
      ],
      "metadata": {
        "id": "iYobXB_kg89k"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Suggest a personalized workout routine for someone looking to improve cardiovascular endurance and prefers outdoor activities.\"\n",
        "print(llm(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQqNPVcDhJAA",
        "outputId": "98cd7358-ebc1-4b33-f501-a8a371c1909c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. Begin with a 10 minutes light jog or brisk walk.\n",
            "2. Follow it up with 30 minutes of interval training. Start with 30 seconds of moderate to high-intensity running, followed by 30 seconds rest. Do this at least 8 times.\n",
            "3. After the interval training, jog for 15 minutes.\n",
            "4. Cool down with a 5-minute walk.\n",
            "5. Repeat this routine at least 3-4 times per week.\n",
            "\n",
            "Additionally, you can add some outdoor activities, such as cycling, swimming, or hiking. You could also add functional exercises such as walking up stairs or hills, using additional bodyweight exercises such as mountain climbers and jumping jacks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Chains"
      ],
      "metadata": {
        "id": "aKgCTGIbntHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "llm = OpenAI(model=\"text-davinci-003\", temperature=0.9)\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"product\"],\n",
        "    template=\"What is a good name for a company that makes {product}?\",\n",
        ")\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n"
      ],
      "metadata": {
        "id": "M3p9bHCknsfu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the chain only specifying the input variable.\n",
        "print(chain.run(\"uniquie data science company name that doesn't have data included int\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKPcYM1IjBsP",
        "outputId": "8fce48e5-8793-4c53-a065-9d9c70c482ad"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "IdeaFlux Data Solutions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Memory"
      ],
      "metadata": {
        "id": "lNw84ilyrwIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "llm = OpenAI(model=\"text-davinci-003\", temperature=0)\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    memory=ConversationBufferMemory()\n",
        ")\n",
        "\n",
        "# Start the conversation\n",
        "conversation.predict(input=\"Tell me about yourself.\")\n",
        "\n",
        "# Continue the conversation\n",
        "conversation.predict(input=\"What can you do?\")\n",
        "conversation.predict(input=\"How can you help me with data analysis?\")\n",
        "\n",
        "# Display the conversation\n",
        "print(conversation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1RJ5SL8pPhI",
        "outputId": "c8d25e56-24dd-4926-b877-ace426961630"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Tell me about yourself.\n",
            "AI:\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-sDvY8QtsGQBaOqMrQ05a5eC2 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Tell me about yourself.\n",
            "AI:  Hi there! I'm an AI created to help people with their daily tasks. I'm programmed to understand natural language and respond to questions and commands. I'm also able to learn from my interactions with people, so I'm constantly growing and improving. I'm excited to help you out!\n",
            "Human: What can you do?\n",
            "AI:\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-sDvY8QtsGQBaOqMrQ05a5eC2 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-sDvY8QtsGQBaOqMrQ05a5eC2 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-sDvY8QtsGQBaOqMrQ05a5eC2 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-sDvY8QtsGQBaOqMrQ05a5eC2 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Tell me about yourself.\n",
            "AI:  Hi there! I'm an AI created to help people with their daily tasks. I'm programmed to understand natural language and respond to questions and commands. I'm also able to learn from my interactions with people, so I'm constantly growing and improving. I'm excited to help you out!\n",
            "Human: What can you do?\n",
            "AI:  I can help you with a variety of tasks, such as scheduling appointments, setting reminders, and providing information. I'm also able to answer questions about topics like current events, sports, and entertainment. I'm always learning new things, so I'm sure I can help you with whatever you need.\n",
            "Human: How can you help me with data analysis?\n",
            "AI:\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-sDvY8QtsGQBaOqMrQ05a5eC2 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-sDvY8QtsGQBaOqMrQ05a5eC2 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "memory=ConversationBufferMemory(chat_memory=ChatMessageHistory(messages=[HumanMessage(content='Tell me about yourself.', additional_kwargs={}, example=False), AIMessage(content=\" Hi there! I'm an AI created to help people with their daily tasks. I'm programmed to understand natural language and respond to questions and commands. I'm also able to learn from my interactions with people, so I'm constantly growing and improving. I'm excited to help you out!\", additional_kwargs={}, example=False), HumanMessage(content='What can you do?', additional_kwargs={}, example=False), AIMessage(content=\" I can help you with a variety of tasks, such as scheduling appointments, setting reminders, and providing information. I'm also able to answer questions about topics like current events, sports, and entertainment. I'm always learning new things, so I'm sure I can help you with whatever you need.\", additional_kwargs={}, example=False), HumanMessage(content='How can you help me with data analysis?', additional_kwargs={}, example=False), AIMessage(content=\" I'm not familiar with data analysis, but I'm sure I can help you find the information you need. I can search the web for articles and resources related to data analysis, and I can also provide you with links to helpful websites.\", additional_kwargs={}, example=False)]), output_key=None, input_key=None, return_messages=False, human_prefix='Human', ai_prefix='AI', memory_key='history') callbacks=None callback_manager=None verbose=True tags=None prompt=PromptTemplate(input_variables=['history', 'input'], output_parser=None, partial_variables={}, template='The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\n\\nCurrent conversation:\\n{history}\\nHuman: {input}\\nAI:', template_format='f-string', validate_template=True) llm=OpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.0, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', batch_size=20, request_timeout=None, logit_bias={}, max_retries=6, streaming=False, allowed_special=set(), disallowed_special='all') output_key='response' output_parser=NoOpOutputParser() return_final_only=True llm_kwargs={} input_key='input'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Lake VectorStore"
      ],
      "metadata": {
        "id": "hroMV70S1gnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deeplake"
      ],
      "metadata": {
        "id": "WwQp_eS_sGDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import DeepLake\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# Before executing the following code, make sure to have your\n",
        "# Activeloop key saved in the “ACTIVELOOP_TOKEN” environment variable.\n",
        "\n",
        "# instantiate the LLM and embeddings models\n",
        "llm = OpenAI(model=\"text-davinci-003\", temperature=0)\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "\n",
        "# create our documents\n",
        "texts = [\n",
        "    \"Napoleon Bonaparte was born in 15 August 1769\",\n",
        "    \"Louis XIV was born in 5 September 1638\"\n",
        "]\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "docs = text_splitter.create_documents(texts)\n",
        "\n",
        "# create Deep Lake dataset\n",
        "# TODO: use your organization id here. (by default, org id is your username)\n",
        "my_activeloop_org_id = \"harbidel\"\n",
        "my_activeloop_dataset_name = \"LangChain_Practice\"\n",
        "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
        "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)\n",
        "\n",
        "# add documents to our Deep Lake dataset\n",
        "db.add_documents(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CevdvBr11E_",
        "outputId": "26d97690-9f42-4c41-e93e-29374c7ca259"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deep Lake Dataset in hub://harbidel/LangChain_Practice already exists, loading from the storage\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.26s/it]\n",
            "100%|██████████| 2/2 [00:04<00:00,  2.05s/it]\n",
            "\\"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset(path='hub://harbidel/LangChain_Practice', tensors=['embedding', 'id', 'metadata', 'text'])\n",
            "\n",
            "  tensor      htype      shape     dtype  compression\n",
            "  -------    -------    -------   -------  ------- \n",
            " embedding  embedding  (6, 1536)  float32   None   \n",
            "    id        text      (6, 1)      str     None   \n",
            " metadata     json      (6, 1)      str     None   \n",
            "   text       text      (6, 1)      str     None   \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r \r"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cc3a77da-706e-11ee-bd30-0242ac1c000c',\n",
              " 'cc3a7942-706e-11ee-bd30-0242ac1c000c']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a retrievalQA\n",
        "\n",
        "retrieval_qa = RetrievalQA.from_chain_type(\n",
        "\tllm=llm,\n",
        "\tchain_type=\"stuff\",\n",
        "\tretriever=db.as_retriever()\n",
        ")"
      ],
      "metadata": {
        "id": "8Hta0MRR24qQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reate an agent that uses the RetrievalQA chain as a tool\n",
        "\n",
        "from langchain.agents import initialize_agent, Tool\n",
        "from langchain.agents import AgentType\n",
        "\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Retrieval QA System\",\n",
        "        func=retrieval_qa.run,\n",
        "        description=\"Useful for answering questions.\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "agent = initialize_agent(\n",
        "\ttools,\n",
        "\tllm,\n",
        "\tagent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "\tverbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "GNkMMLHdlQ-j"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the agent to ask question\n",
        "\n",
        "response = agent.run(\"When was Napoleone born?\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PREaSRVwlqao",
        "outputId": "7cc01cb8-8bc2-47bb-d152-d0e2b2c85461"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to find out when Napoleone was born.\n",
            "Action: Retrieval QA System\n",
            "Action Input: When was Napoleone born?\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-sDvY8QtsGQBaOqMrQ05a5eC2 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-sDvY8QtsGQBaOqMrQ05a5eC2 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-sDvY8QtsGQBaOqMrQ05a5eC2 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-sDvY8QtsGQBaOqMrQ05a5eC2 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Observation: \u001b[36;1m\u001b[1;3m Napoleon Bonaparte was born on 15 August 1769.\u001b[0m\n",
            "Thought:"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-sDvY8QtsGQBaOqMrQ05a5eC2 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-sDvY8QtsGQBaOqMrQ05a5eC2 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-sDvY8QtsGQBaOqMrQ05a5eC2 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: Napoleon Bonaparte was born on 15 August 1769.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Napoleon Bonaparte was born on 15 August 1769.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the existing Deep Lake dataset and specify the embedding function\n",
        "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)\n",
        "\n",
        "# create new documents\n",
        "texts = [\n",
        "    \"Lady Gaga was born in 28 March 1986\",\n",
        "    \"Michael Jeffrey Jordan was born in 17 February 1963\"\n",
        "]\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "docs = text_splitter.create_documents(texts)\n",
        "\n",
        "# add documents to our Deep Lake dataset\n",
        "db.add_documents(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXiUOJv-lyFd",
        "outputId": "cd76ac76-6024-41bb-a9e8-5d52013bb2de"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deep Lake Dataset in hub://harbidel/LangChain_Practice already exists, loading from the storage\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating embeddings: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.49it/s]\n",
            "/"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset(path='hub://harbidel/LangChain_Practice', tensors=['embedding', 'id', 'metadata', 'text'])\n",
            "\n",
            "  tensor      htype      shape     dtype  compression\n",
            "  -------    -------    -------   -------  ------- \n",
            " embedding  embedding  (8, 1536)  float32   None   \n",
            "    id        text      (8, 1)      str     None   \n",
            " metadata     json      (8, 1)      str     None   \n",
            "   text       text      (8, 1)      str     None   \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r \r"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ecab3ed2-706e-11ee-bd30-0242ac1c000c',\n",
              " 'ecab4026-706e-11ee-bd30-0242ac1c000c']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate the wrapper class for GPT3\n",
        "llm = OpenAI(model=\"text-davinci-003\", temperature=0)\n",
        "\n",
        "# create a retriever from the db\n",
        "retrieval_qa = RetrievalQA.from_chain_type(\n",
        "\tllm=llm, chain_type=\"stuff\", retriever=db.as_retriever()\n",
        ")\n",
        "\n",
        "# instantiate a tool that uses the retriever\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Retrieval QA System\",\n",
        "        func=retrieval_qa.run,\n",
        "        description=\"Useful for answering questions.\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "# create an agent that uses the tool\n",
        "agent = initialize_agent(\n",
        "\ttools,\n",
        "\tllm,\n",
        "\tagent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "\tverbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "hXUDK3nhmgJr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.run(\"When was Michael Jordan born?\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHvKIjVPmulY",
        "outputId": "8692fcfe-775a-4cf1-a766-63bab4925ddb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-sDvY8QtsGQBaOqMrQ05a5eC2 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-sDvY8QtsGQBaOqMrQ05a5eC2 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m I need to find out when Michael Jordan was born.\n",
            "Action: Retrieval QA System\n",
            "Action Input: When was Michael Jordan born?\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-sDvY8QtsGQBaOqMrQ05a5eC2 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-sDvY8QtsGQBaOqMrQ05a5eC2 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-sDvY8QtsGQBaOqMrQ05a5eC2 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-sDvY8QtsGQBaOqMrQ05a5eC2 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-sDvY8QtsGQBaOqMrQ05a5eC2 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Observation: \u001b[36;1m\u001b[1;3m Michael Jordan was born on 17 February 1963.\u001b[0m\n",
            "Thought:"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-sDvY8QtsGQBaOqMrQ05a5eC2 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-sDvY8QtsGQBaOqMrQ05a5eC2 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-sDvY8QtsGQBaOqMrQ05a5eC2 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: Michael Jordan was born on 17 February 1963.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Michael Jordan was born on 17 February 1963.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "from langchain.agents import AgentType\n",
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent\n",
        "\n",
        "from langchain.agents import Tool\n",
        "from langchain.utilities import GoogleSearchAPIWrapper"
      ],
      "metadata": {
        "id": "hcSwIIj2myMu"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize LLM and set temp to zero\n",
        "\n",
        "llm = OpenAI(model=\"text-davinci-003\", temperature=0)"
      ],
      "metadata": {
        "id": "C-XTDfQaqYa1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remember to set the environment variables\n",
        "# “GOOGLE_API_KEY” and “GOOGLE_CSE_ID” to be able to use\n",
        "# Google Search via API.\n",
        "search = GoogleSearchAPIWrapper()"
      ],
      "metadata": {
        "id": "7ISWfLjIqquz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [\n",
        "    Tool(\n",
        "        name = \"google-search\",\n",
        "        func=search.run,\n",
        "        description=\"useful for when you need to search google to answer questions about current events\"\n",
        "    )\n",
        "]"
      ],
      "metadata": {
        "id": "qzzMJTqCqvb8"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creat an agent that uses our Google search tool\n",
        "\n",
        "agent = initialize_agent(tools,\n",
        "                         llm,\n",
        "                         agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "                         verbose=True,\n",
        "                         max_iterations=6)"
      ],
      "metadata": {
        "id": "SbxauvtMrI32"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the response\n",
        "\n",
        "response = agent(\"What's the latest news about LLMs?\")\n",
        "print(response['output'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8c06cD7rlUL",
        "outputId": "0878207f-1afd-4acf-9c11-75ee0c92ccc5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should search for recent news articles about LLMs.\n",
            "Action: google-search\n",
            "Action Input: \"LLM news\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mSep 13, 2023 ... Hugging Face announced Falcon 180B, the most powerful open source LLM ever. It rivals Google's Palm 2... And it has no guardrails. Jul 24, 2023 ... Generative AI News – Llama 2 Shakes up LLM Market, GPT-4 May Not Be Degrading, Apple GPT, Wix, AP, AI21, SAP, and More – Voicebot Podcast 340. Sign up to get the latest news about large language models (LLM) technologies from NVIDIA. Jul 25, 2023 ... TechScape: Will Meta's open-source LLM make AI safer – or put it into the wrong hands? ... news in the field has gone from weekly to almost daily. Jul 11, 2023 ... ITPro Today: IT News, How-Tos, Trends, Case Studies, Career · Search · Log In · Register · NEWSLETTER SIGN-UP. Recent. Recent. Accidental ... Sep 11, 2023 ... AskIt offers type-guided output control, template-based function definitions, and a unified interface that bridges the gap between LLM-based ... Jun 9, 2023 ... She told Healthcare IT News in December that after finding that UVA Health's 30-day readmission rate for patients with complex and costly ... Jul 6, 2023 ... ... LLM to generate news summaries. A News Summary Generator (NSG) is designed to select and evolve the event pattern populations and generate ... Apr 13, 2021 ... The latest news and updates for the online Master of Laws (LLM) degree program at Northeastern University. Though the term large language model has no formal definition, it generally refers to deep learning models having a parameter count on the order of billions ...\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: Recent news about LLMs includes the announcement of Falcon 180B, the most powerful open source LLM ever, Llama 2 shaking up the LLM market, Meta's open-source LLM, AskIt offering type-guided output control, UVA Health's 30-day readmission rate, and the use of LLMs to generate news summaries.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Recent news about LLMs includes the announcement of Falcon 180B, the most powerful open source LLM ever, Llama 2 shaking up the LLM market, Meta's open-source LLM, AskIt offering type-guided output control, UVA Health's 30-day readmission rate, and the use of LLMs to generate news summaries.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tools in LangChain"
      ],
      "metadata": {
        "id": "X8Qm4rFluvBG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.agents import Tool\n",
        "from langchain.utilities import GoogleSearchAPIWrapper\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.agents import initialize_agent, AgentType"
      ],
      "metadata": {
        "id": "YST_zhz8rvCp"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We then instantiate a  LLMChain specifically for text summarization.\n",
        "\n",
        "llm = OpenAI(model=\"text-davinci-003\", temperature=0)\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"query\"],\n",
        "    template=\"Write a summary of the following text: {query}\"\n",
        ")\n",
        "\n",
        "summarize_chain = LLMChain(llm=llm, prompt=prompt)"
      ],
      "metadata": {
        "id": "muDOawp-vFrY"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we create the tools that our agent will use.\n",
        "\n",
        "# remember to set the environment variables\n",
        "# “GOOGLE_API_KEY” and “GOOGLE_CSE_ID” to be able to use\n",
        "# Google Search via API.\n",
        "search = GoogleSearchAPIWrapper()\n",
        "\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Search\",\n",
        "        func=search.run,\n",
        "        description=\"useful for finding information about recent events\"\n",
        "    ),\n",
        "    Tool(\n",
        "       name='Summarizer',\n",
        "       func=summarize_chain.run,\n",
        "       description='useful for summarizing texts'\n",
        "    )\n",
        "]"
      ],
      "metadata": {
        "id": "3D7Rxga3vXnj"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create our agent that leverages two tools.\n",
        "\n",
        "agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "K9wkdDkUvnAK"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let’s run the agent with a question about summarizing the latest news about the Mars rover.\n",
        "\n",
        "response = agent(\"What's the latest news about the Mars rover? Then please summarize the results.\")\n",
        "print(response['output'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeTFDxhDvu3H",
        "outputId": "00cf8d05-5fba-4283-d098-e12f4b95119b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to find the latest news about the Mars rover and then summarize it.\n",
            "Action: Search\n",
            "Action Input: Latest news about the Mars rover\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mData sent by the spacecraft before it retired last December has provided new details about how fast the planet fast rotates and how much it wobbles. Dec 15, 2021 ... Mars Sample Return is going to have great stuff to choose from!” Get the Latest JPL News. SUBSCRIBE TO THE NEWSLETTER. The multi-mission Mars ... NASA's Curiosity Mars rover captured these clouds just after sunset on March 19, 2021, ... Curiosity rover finds water-carved 'book' rock on Mars (photo) ... A book-shaped rock on Mars was likely carved by ancient water running through the area, ... NASA's Mars 2020 Perseverance rover will look for signs of past microbial life, cache rock and soil samples, and prepare for future human exploration. Curiosity Rover · Nasa's Curiosity Mars rover can provide a lot of information about the Red Planet, but · An image taken by the Nasa Spirit rover, which shows ... Feb 8, 2023 ... NASA's Curiosity Mars rover has discovered lots of evidence of ancient lakes on the Red Planet – and this recent panorama shows intriguing ... Jun 28, 2023 ... Informally dubbed by Hecht and his team as \"the last hurrah,\" MOXIE delivered the goods on its 15th run on Mars since first gulping up Martian ... Apr 28, 2023 ... A new study suggests water on Mars may be more widespread and recent than previously thought. Scientists reported the finding from China's ... Apr 25, 2023 ... China's Mars rover, which has been in longer-than-expected hibernation on the red planet since May 2022, has likely suffered excessive ...\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now need to summarize the results.\n",
            "Action: Summarizer\n",
            "Action Input: Data sent by the spacecraft before it retired last December has provided new details about how fast the planet fast rotates and how much it wobbles. Dec 15, 2021 ... Mars Sample Return is going to have great stuff to choose from!” Get the Latest JPL News. SUBSCRIBE TO THE NEWSLETTER. The multi-mission Mars ... NASA's Curiosity Mars rover captured these clouds just after sunset on March 19, 2021, ... Curiosity rover finds water-carved 'book' rock on Mars (photo) ... A book-shaped rock on Mars was likely carved by ancient water running through the area, ... NASA's Mars 2020 Perseverance rover will look for signs of past microbial life, cache rock and soil samples, and prepare for future human exploration. Curiosity Rover · Nasa's Curiosity Mars rover can provide a lot of information about the Red Planet, but · An image taken by the Nasa Spirit rover, which shows ... Feb 8, 2023 ... NASA's Curiosity Mars rover has discovered lots of evidence of ancient lakes on the Red Planet – and this recent panorama shows intriguing ... Jun 28, 2023 ... Informally dubbed by He\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-sDvY8QtsGQBaOqMrQ05a5eC2 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Observation: \u001b[33;1m\u001b[1;3mcht as the \"Mars wobble,\" the data sent by the spacecraft before it retired last December has provided new details about how fast the planet rotates and how much it wobbles.\n",
            "\n",
            "NASA's Curiosity Mars rover has been providing a wealth of information about the Red Planet since its launch in 2021. Recently, data sent by the spacecraft before it retired last December has revealed new details about the planet's rotation and wobble. This \"Mars wobble\" was informally dubbed by Hecht and provides insight into the planet's speed of rotation and the amount of wobble it experiences. In addition, the Mars Sample Return mission is set to launch in 2021, and the Mars 2020 Perseverance rover will look for signs of past microbial life and cache rock and soil samples. The Curiosity rover has also discovered evidence of ancient lakes on the Red Planet.\u001b[0m\n",
            "Thought:"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-sDvY8QtsGQBaOqMrQ05a5eC2 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-sDvY8QtsGQBaOqMrQ05a5eC2 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: The Curiosity rover has been providing a wealth of information about the Red Planet since its launch in 2021, including new details about the planet's rotation and wobble, as well as evidence of ancient lakes. The Mars Sample Return mission is set to launch in 2021, and the Mars 2020 Perseverance rover will look for signs of past microbial life and cache rock and soil samples.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "The Curiosity rover has been providing a wealth of information about the Red Planet since its launch in 2021, including new details about the planet's rotation and wobble, as well as evidence of ancient lakes. The Mars Sample Return mission is set to launch in 2021, and the Mars 2020 Perseverance rover will look for signs of past microbial life and cache rock and soil samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IMz0KGoov301"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}